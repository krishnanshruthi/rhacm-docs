[#global-hub-configuring-cronjobs]
= Configuring the cron jobs

You can configure the cron job settings of the {global-hub}. 

After installing the {global-hub} operand, the {global-hub} manager runs and displays a job scheduler for you to schedule the following cron jobs:

* Local compliance status sync job: This cron job runs at midnight every day, based on the policy status and events collected by the manager on the previous day. Running this job summarizes the compliance status and the change frequency of the policy on the cluster, and stores them to the `history.local_compliance` table as the data source of the Grafana dashboards. 

* Data retention job: Some data tables in {global-hub} continue to grow over time, which normally can cause problems when the tables get too large. The following two methods help to minimize the issues that result from tables that are too large:

** Deleting older data that is no longer needed

** Enabling partitioning on the large table to run queries and deletions on faster
+
For event tables like the `event.local_policies` and the `history.local_compliance` that increase in size daily, range partitioning divides the large tables into smaller partitions. This process also creates the partition tables for the next month each time it is run. For the policy and cluster tables like `local_spec.policies` and `status.managed_clusters`, there are `deleted_at` indexes on the tables to improve performance when hard deleting.
+
You can change the duration of time that the data is retained by changing the `retention` setting on the {global-hub} operand. The recommended minimum value is 1 month, and the default value is 18 months. The run interval of this job should be less than one month.

The listed cron jobs run every time the {global-hub} manager starts. The local compliance status sync job is run once a day and can be run multiple times within the day without changing the result. The data retention job is run once a week and also can be run many times per month without a change in the results. 

The status of these jobs are are saved in the metrics named `multicluster_global_hub_jobs_status`, which can be viewed from the console of the {ocp} cluster. A value of `0` indicates that the job ran successfully, while a value of `1` indicates failure. 

If there is a failed job, you can troubleshoot by using the log tables (`history.local_compliance_job_log`, `event.data_retention_job_log`). See link:../troubleshooting/global_hub_trouble_cron job_compliance_data_restore.adoc#gh-cronjob-compliance-data-restore[Restoring compliance data] for more details and for guidance for deciding whether to run the service manually.
